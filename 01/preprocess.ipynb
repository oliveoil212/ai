{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import math\n",
    "import random\n",
    "import copy\n",
    "import json\n",
    "\n",
    "# from simcse import SimCSE\n",
    "from sklearn import *\n",
    "# from transformers import BertTokenizer\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "#from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Load node data ################\n",
    "code2name = pd.read_csv('./FB15k237/FB15k_mid2name.txt', sep=\"\\t\", header=None, names=['code', 'name'])\n",
    "code2desciption = pd.read_csv('./FB15k237/FB15k_mid2description.txt', sep=\"\\t\", header=None, names=['code', 'description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Merge node data and Shorten description ####\n",
    "def description_cleanser(descript):\n",
    "    delimiters = \".\", \";\"\n",
    "    regex_pattern = '|'.join(map(re.escape, delimiters))\n",
    "    new_description = re.split(regex_pattern, descript, 1)[0]\n",
    "    new_description = new_description.replace('\\*', '').replace('\\\\', '').replace('\\*\\\\', '').replace('\\\"', '') # remove '*' '/' '\"'\n",
    "    new_description = new_description.replace('_', ' ') # replace '_' with ' '\n",
    "    return new_description\n",
    "\n",
    "code2desciption['description'] = code2desciption['description'].apply(description_cleanser)\n",
    "node_info = code2name.merge(code2desciption, how='outer', on='code').set_index('code') \n",
    "# del code2name, code2desciption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def data_parser(data):\n",
    "#     df = pd.DataFrame(columns=[\"head_code\",\"head_name\",\"head_desciption\",\"relation\",\"tail_code\", \"tail_name\",\"tail_desciption\"])\n",
    "#     for index, row in data.iterrows():\n",
    "#         relations = row['relations'].split('/')[1:]\n",
    "#         head_code = row['head_code']\n",
    "#         head_name = node_info.loc[head_code, 'name']\n",
    "#         head_desciption = node_info.loc[head_code, 'description']\n",
    "#         tail_code = row['tail_code']\n",
    "#         tail_name = node_info.loc[tail_code, 'name']\n",
    "#         tail_desciption = node_info.loc[tail_code, 'description']\n",
    "\n",
    "        \n",
    "#         for relation in relations:\n",
    "#             entry = pd.DataFrame.from_dict({ # 我不知道為什麼要用[]包起來==\n",
    "#                 \"head_code\": [head_code],\n",
    "#                 \"head_name\": [head_name],\n",
    "#                 \"head_desciption\": [head_desciption],\n",
    "#                 \"relation\": [relation],\n",
    "#                 \"tail_code\": [tail_code],\n",
    "#                 \"tail_name\": [tail_name],\n",
    "#                 \"tail_desciption\": [tail_desciption]\n",
    "#             })\n",
    "#             df= pd.concat([df, entry], ignore_index=True)\n",
    "#            \n",
    "#     return df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_val = pd.read_csv('./FB15k237/valid.txt', sep=\"\\t\", header=None, names=['head_code', 'relations', 'tail_code'])\n",
    "raw_data_train = pd.read_csv('./FB15k237/train.txt', sep=\"\\t\", header=None, names=['head_code', 'relations', 'tail_code'])\n",
    "raw_data_merge =  pd.concat([raw_data_train, raw_data_val], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check = list(df.duplicated())\n",
    "# for i in check:\n",
    "#     if i != False:\n",
    "#         print(i.index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=[\"head_code\",\"head_name\",\"head_desciption\",\"relation\",\"tail_code\", \"tail_name\",\"tail_desciption\"])\n",
    "for index, row in raw_data_merge.iterrows():\n",
    "        # relations = row['relations'].split('/')[1:]\n",
    "        relations = row['relations']\n",
    "        head_code = row['head_code']\n",
    "        head_name = node_info.loc[head_code, 'name']\n",
    "        head_desciption = node_info.loc[head_code, 'description']\n",
    "        tail_code = row['tail_code']\n",
    "        tail_name = node_info.loc[tail_code, 'name']\n",
    "        tail_desciption = node_info.loc[tail_code, 'description']\n",
    "        \n",
    "\n",
    "        entry = pd.DataFrame.from_dict({ # 我不知道為什麼要用[]包起來==\n",
    "            \"head_code\": [head_code],\n",
    "            \"head_name\": [head_name],\n",
    "            \"head_desciption\": [head_desciption],\n",
    "            \"relation\": [relations],\n",
    "            \"tail_code\": [tail_code],\n",
    "            \"tail_name\": [tail_name],\n",
    "            \"tail_desciption\": [tail_desciption]\n",
    "        })\n",
    "        df= pd.concat([df, entry], ignore_index=True)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0ce25ab49341897cf661f86cfd509ad4042cbd8be4afd81cd4b6396d83d26f95"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
